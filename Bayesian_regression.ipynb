{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@\n",
    "#Bayesian regression\n",
    "#Jeremy Kedziora\n",
    "#4/20/2016\n",
    "#@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "import numpy as np    #import numpy\n",
    "import scipy    #import scipy\n",
    "from scipy.stats import invgamma as IG    #import scipy stats for the inverse gamma\n",
    "import matplotlib.pyplot as plt    #import to visualize and plot\n",
    "from math import ceil    #import the ceiling function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta_sampler(X,y,beta,sigma2):\n",
    "    \n",
    "    \"\"\"A function to sample a single draw of the betas from the posterior in a bayesian regression.\n",
    "    Take as inputs:\n",
    "    X: a numpy array of independent variables\n",
    "    y: a numpy array of the dependent variable\n",
    "    beta: a list of lists of initial values for beta\n",
    "    sigma2: a list of the initial value for sigma2\n",
    "    mu: an array of prior means for the parameters\n",
    "    t2: an array of prior variances for the parameters\n",
    "    \"\"\"\n",
    "    t = len(beta[0])    #the time step\n",
    "    mean = np.linalg.inv(X.dot(X.T)).dot(X.dot(y))    #compute the mean of the multivariate normal\n",
    "    Sigma_matrix = sigma2[t-1]*np.linalg.inv(X.dot(X.T))    #compute the sigma matrix\n",
    "    draw = np.random.multivariate_normal(mean,Sigma_matrix)    #draw from the posterior of beta\n",
    "    \n",
    "    for j in range(len(beta)):    #loop over beta parameters\n",
    "        beta[j] = beta[j] + [draw[j]]    #and add the parameter to the list\n",
    "        \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma2_sampler(X,y,beta,sigma2):\n",
    "    \n",
    "    \"\"\"A function to sample a single draw of the sigma2 from the posterior in a bayesian regression.\n",
    "    Take as inputs:\n",
    "    X: a numpy array of independent variables\n",
    "    y: a numpy array of the dependent variable\n",
    "    beta: a list of lists of initial values for beta\n",
    "    sigma2: a list of the initial value for sigma2\n",
    "    mu: an array of prior means for the parameters\n",
    "    t2: an array of prior variances for the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    t = len(beta[0])    #the time step\n",
    "    b = []    #initialize a list to hold the current values of b\n",
    "    for beta_j in beta:    #loop over the variable effects\n",
    "        b.append(beta_j[t-1])    #and take the last draw for each variable\n",
    "    b = np.array(b)    #make them into an array for matrix multiplication\n",
    "    parameter_1 = (X.shape[1] - X.shape[0])/2.0    #the first parameter in the inverse gamma\n",
    "    parameter_2 = sum((y - X.T.dot(b))**2.0)/2.0    #the second parameter in the inverse gamma\n",
    "    draw = 1.0/np.random.gamma(parameter_1,1.0/parameter_2)    #draw from the posterior distribution\n",
    "    \n",
    "    return sigma2 + [draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MCMC(n_sim,X,y):\n",
    "    \n",
    "    \"\"\"A function to run Gibb's sampling to estimate the posterior of linear model parameters.\n",
    "    Take as inputs:\n",
    "    n_sim: how many simulations you want to run\n",
    "    X: a numpy array of independent variables\n",
    "    y: a numpy array of the dependent variable\n",
    "    beta: a list of lists of initial values for beta\n",
    "    sigma2: a list of the initial value for sigma2\n",
    "    mu: an array of prior means for the parameters\n",
    "    t2: an array of prior variances for the parameters    \n",
    "    \"\"\"\n",
    "    \n",
    "    #specify initial values for beta and sigma\n",
    "    beta_t = [[0.0]]*X.shape[0]    #set betas initially to zero\n",
    "    sigma2_t = [1.0]    #set sigma2 initially to 1.0\n",
    "    for _ in range(n_sim):    #loop over simulations\n",
    "        beta_t = beta_sampler(X,y,beta_t,sigma2_t)    #sample beta\n",
    "        sigma2_t = sigma2_sampler(X,y,beta_t,sigma2_t)    #sample sigma2\n",
    "    \n",
    "    return [beta_t,sigma2_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior_summary(posterior,path):\n",
    "    \"\"\"A function to compute posterior summary statistics.\n",
    "    Take as inputs:\n",
    "    beta: a numpy array of samples from the posterior distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    beta_means = np.mean(posterior,1)    #compute the mean of the posterior\n",
    "    beta_HPD = [np.percentile(posterior,0.975,1),np.percentile(posterior,0.025,1)]    #compute the 95% region of highest posterior density\n",
    "    p_positive = np.sum(np.array(posterior)>0,1)/len(posterior[0])    #compute the probability the parameter is positive\n",
    "    for j in range(len(beta_means)):    #loop over variables\n",
    "        print('For','x'+str(j),'the posterior mean is:',round(beta_means[j],4),'.')    #print the mean of the posterior\n",
    "        print('The 95% HPD is: [',round(beta_HPD[1][j],4),round(beta_HPD[0][j],4),'].')    #print the 95% CI\n",
    "        print('The probability that the effect is positive is: ',round(p_positive[j],4),'.')    #print the probability that the parameter has a positive effect\n",
    "        print('____________________________________________________________________')\n",
    "    \n",
    "    plt.figure(figsize = (20,10))    #initiate the plot\n",
    "    n_plots = ceil(len(beta_means)**0.5)    #how many plots to make\n",
    "    for j in range(len(posterior)):    #loop over variables\n",
    "        plt.subplot(n_plots,n_plots,j+1)    #plot subplot 1,1 in the 3x3 area\n",
    "        plt.plot(posterior[j],'b-',lw=4)    #generate the plot\n",
    "        plt.xlabel('Gibbs Sampler Iteration',fontsize=20)    #add an x label\n",
    "        plt.ylabel(r'$\\beta$'+str(j),fontsize=20)    #add a y label\n",
    "\n",
    "    plt.savefig(path)    #save the plot to file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For x0 the posterior mean is: 1.0028 .\n",
      "The 95% HPD is: [ 0.2263 0.9296 ].\n",
      "The probability that the effect is positive is:  0.999 .\n",
      "____________________________________________________________________\n",
      "For x1 the posterior mean is: 2.0127 .\n",
      "The 95% HPD is: [ 0.4724 1.9301 ].\n",
      "The probability that the effect is positive is:  0.999 .\n",
      "____________________________________________________________________\n",
      "For x2 the posterior mean is: -1.5025 .\n",
      "The 95% HPD is: [ -1.6173 -1.58 ].\n",
      "The probability that the effect is positive is:  0.0 .\n",
      "____________________________________________________________________\n",
      "For x3 the posterior mean is: -0.9905 .\n",
      "The 95% HPD is: [ -1.0888 -1.0719 ].\n",
      "The probability that the effect is positive is:  0.0 .\n",
      "____________________________________________________________________\n",
      "For x4 the posterior mean is: 1.7767 .\n",
      "The 95% HPD is: [ 0.419 1.7021 ].\n",
      "The probability that the effect is positive is:  0.999 .\n",
      "____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#make fake data\n",
    "N = 1000    #the number of observations\n",
    "x_1 = np.random.normal(0,1,N)    #the independent variable\n",
    "x_2 = np.random.normal(0,1,N)    #the independent variable\n",
    "x_3 = np.random.normal(0,1,N)    #the independent variable\n",
    "x_4 = np.random.normal(0,1,N)    #the independent variable\n",
    "e = np.random.normal(0,1,N)    #the error\n",
    "y = 1.0 + 2.0*x_1 - 1.5*x_2 - 1.0*x_3 + 1.75*x_4 + e    #the dependent variable\n",
    "X = np.array([[1.0]*N,x_1,x_2,x_3,x_4])    #put the independent variables together\n",
    "\n",
    "#call the MCMC routine\n",
    "n_sim = 1000    #specify the number of simulations\n",
    "Posterior = MCMC(n_sim,X,y)    #sample from the posterior\n",
    "\n",
    "#call the summary function to make inferences\n",
    "path = '/Users/seniordatascientist/Desktop/Metis Codes/Posterior.pdf'    #specify where I want to write graphs\n",
    "posterior_summary(Posterior[0],path)    #compute summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
