{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#A code to run ordinary least squares with associated statistics\n",
    "#Jeremy Kedziora\n",
    "#24 March 2016\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "#import libraries\n",
    "import numpy as np    #import for arrays\n",
    "from scipy.optimize import minimize    #import for optimization\n",
    "import scipy.stats\n",
    "import statsmodels as sm\n",
    "from scipy.stats import t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define functions\n",
    "def maker(N,n_vars,kind = 'linear',n_cat = 0):\n",
    "    \"\"\"A function to generate Monte Carlo linear regression data\"\"\"\n",
    "    x = []    #an empty list to hold the data\n",
    "    y = np.zeros(N)    #an array to hold the dependent variable\n",
    "    b = []    #an empty list to hold the true bs\n",
    "    mu = [0.0]    #an empty list to hold the true cutoffs in the ordered probit\n",
    "    i = 1\n",
    "    while i <= n_vars:    #loop over the variables we want to create\n",
    "        x_i = np.random.normal(loc = 0.0, scale = 1.0, size = N)    #generate the data\n",
    "        x.append(x_i)    #add it to the list of data\n",
    "        b_i = np.random.normal(loc = 0.0, scale = 1.0)    #draw a random effect for this variable\n",
    "        b.append(b_i)    #add it to the list of effects\n",
    "        y = y + b_i*x_i    #add the variable effect to the dependent variable\n",
    "        i += 1    #index up i\n",
    "    \n",
    "    x.append(np.ones(N))    #and a column of ones for a constant\n",
    "    b_i = np.random.uniform(0.0,1.0)    #draw a random intercept\n",
    "\n",
    "    if kind == 'linear':\n",
    "        y = b_i + y + np.random.normal(loc = 0.0, scale = 1.0, size = N)    #add the normally distributed error term and the intercept\n",
    "    if kind == 'logit':\n",
    "        y = (np.random.uniform(0,1,len(y)) < np.exp(b_i + y)/(1 + np.exp(b_i + y)))*1    #draw y values\n",
    "    if kind == 'ordered':\n",
    "        y = b_i + y + np.random.normal(loc = 0.0, scale = 1.0, size = N)    #add the normally distributed error term and the intercept\n",
    "        for i in range(n_cat-2):    #loop over number of categories\n",
    "            mu.append(mu[i] + np.random.uniform(0.25,1,1)[0])    #append the cutoff for the next category\n",
    "        y_cat = (y<mu[0])*0    #set the ys less than 0 to category 0\n",
    "        for i in range(1,len(mu)):    #loop over the remaining categories\n",
    "            y_cat = y_cat + (mu[i-1]<y)*(y<mu[i])*i    #code all the ys that fall between them\n",
    "        y_cat = y_cat + (y>mu[len(mu)-1])*(n_cat - 1)    #and code all the ys larger than the largest\n",
    "        y = y_cat    #and save\n",
    "    if kind == 'count':\n",
    "        b_i = np.random.uniform(-1.0,0)    #draw a random intercept\n",
    "        y = np.random.poisson(np.exp(b_i + y))    #draw the counts\n",
    "    b.append(b_i)    #append this intercept to the effects\n",
    "    return [np.array(x).T,np.array(y),np.array(b),np.array(mu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poisson_mle(b,X,y):\n",
    "    \"\"\"A function to compute the poisson log-likelihood.\"\"\"\n",
    "    xb = X.dot(b)    #compute xb\n",
    "    return -1*sum(y*xb - np.exp(xb))    #compute the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ordered_probit_mle(b,X,y):\n",
    "    \"\"\"A function to compute the ordered probit log-likelihood.\"\"\"\n",
    "    xb = X.dot(b[0:(X.shape[1])])    #compute xb\n",
    "    mu = [float('-inf'),0]    #initialize the list of mus\n",
    "    for i in range(len(b[X.shape[1]:])):    #loop over categories\n",
    "        mu = mu + [mu[i+1] + b[X.shape[1]:][i]]    #and create each mu\n",
    "    mu = mu + [float('inf')]    #append infinity on the end\n",
    "    probs = np.zeros(len(y))    #set up an array of 0s\n",
    "    for i in range(1,len(set(y)) + 1):    #loop over categories\n",
    "        probs = probs + (scipy.stats.norm.cdf(mu[i] - xb) - scipy.stats.norm.cdf(mu[i - 1] - xb))*(y == list(set(y))[i-1])    #compute probability\n",
    "    return -1*sum(np.log(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta estimated by MLE:       [-0.18315886  0.62673498  0.85678992 -0.76198332]\n",
      "Beta used to generate data:  [-0.23071022  0.66526728  0.86814841 -0.8919839 ]\n",
      "[  2.30043220e-01   2.24761510e-06   5.86006111e-07   9.48835362e-05]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "n_vars = 3\n",
    "Data = maker(N,n_vars,'count')    #make poisson data\n",
    "X = Data[0]    #pull out the features\n",
    "y = Data[1]    #pull out the labels\n",
    "\n",
    "b = np.random.uniform(0,1,4)*0.01    #set starting values\n",
    "model = minimize(poisson_mle, x0 = b, args = (X,y), method = 'BFGS')    #maximize the log-likelihood\n",
    "Coefficients = model.x    #pull out the coefficients\n",
    "SE = np.diag(model.hess_inv)**0.5\n",
    "t_stat = Coefficients/SE    #compute the t statistics for each variable\n",
    "p_values = 2*t.pdf(abs(t_stat),df = N - 1)    #compute the p-values\n",
    "\n",
    "print('Beta estimated by MLE:      ',Coefficients)\n",
    "print('Beta used to generate data: ',Data[2])\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta estimated by MLE:       [ 124580.05342331  224967.27454416  639867.30225533  468002.48762422\n",
      " -500062.63425663]\n",
      "Beta used to generate data:  [0.28905599203326476, 0.53508539388182164, 1.55885872411638, 0.82693594880086951, 0.72848728209441937]\n",
      "[ 0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "n_vars = 3\n",
    "Data = maker(N,n_vars,'ordered',n_cat=3)    #make poisson data\n",
    "X = Data[0]    #pull out the features\n",
    "y = Data[1]    #pull out the labels\n",
    "\n",
    "b = np.array(list(np.random.uniform(0,1,X.shape[1])*0.01) + list(np.random.uniform(0,1.0,len(set(y))-2)))\n",
    "model = minimize(ordered_probit_mle, x0 = b, args = (X,y), method = 'BFGS')    #maximize the log-likelihood\n",
    "Coefficients = model.x    #pull out the coefficients\n",
    "SE = np.diag(model.hess_inv)**0.5\n",
    "t_stat = Coefficients/SE    #compute the t statistics for each variable\n",
    "p_values = 2*t.pdf(abs(t_stat),df = N - 1)    #compute the p-values\n",
    "\n",
    "print('Beta estimated by MLE:      ',Coefficients)\n",
    "print('Beta used to generate data: ',list(Data[2]) + list(Data[3][1:]))\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
